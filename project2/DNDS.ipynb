{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "32d8c90a-1480-4133-b3e6-fb15a638897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class          N  S  dNdS_naive\n",
      "Hugo_Symbol                    \n",
      "TP53         169  2   84.500000\n",
      "ERBB2         33  1   33.000000\n",
      "SMAD4         29  1   29.000000\n",
      "CFH           28  1   28.000000\n",
      "PIK3CA        82  3   27.333333\n",
      "CDH9          25  1   25.000000\n",
      "CNTN4         25  1   25.000000\n",
      "GRIN3A        24  1   24.000000\n",
      "THSD1         23  1   23.000000\n",
      "AMY2B         21  1   21.000000\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load mutation file FINAL\n",
    "mut_df = pd.read_csv(\"TCGA.STAD.mutations.txt\", sep=\"\\t\")\n",
    "\n",
    "# Step 1.5: Keep only SNPs\n",
    "mut_df = mut_df[mut_df['Variant_Type'] == 'SNP']\n",
    "\n",
    "# Step 2: Filter for coding mutations of interest\n",
    "syn = ['Silent']\n",
    "nonsyn = ['Missense_Mutation', 'Nonsense_Mutation']\n",
    "mut_df = mut_df[mut_df['Variant_Classification'].isin(syn + nonsyn)]\n",
    "\n",
    "# Step 3: Remove hypermutator samples (e.g. top 1% by mutation load)\n",
    "mut_counts = mut_df['Tumor_Sample_Barcode'].value_counts()\n",
    "threshold = mut_counts.quantile(0.99)\n",
    "keep_samples = mut_counts[mut_counts <= threshold].index\n",
    "mut_df = mut_df[mut_df['Tumor_Sample_Barcode'].isin(keep_samples)]\n",
    "\n",
    "# Step 4: Classify mutations as synonymous or nonsynonymous\n",
    "mut_df['class'] = mut_df['Variant_Classification'].apply(lambda x: 'syn' if x in syn else 'nonsyn')\n",
    "\n",
    "# Step 5: Count N and S per gene\n",
    "counts = mut_df.groupby(['Hugo_Symbol', 'class']).size().unstack(fill_value=0)\n",
    "counts = counts.rename(columns={'syn': 'S', 'nonsyn': 'N'})\n",
    "\n",
    "# Ensure both columns exist\n",
    "if 'N' not in counts.columns:\n",
    "    counts['N'] = 0\n",
    "if 'S' not in counts.columns:\n",
    "    counts['S'] = 0\n",
    "\n",
    "# Step 6: Compute naive dN/dS (exclude genes with S = 0)\n",
    "counts = counts[counts['S'] > 0]\n",
    "counts['dNdS_naive'] = counts['N'] / counts['S']\n",
    "\n",
    "# Step 7: View top candidates\n",
    "top = counts.sort_values('dNdS_naive', ascending=False).head(10)\n",
    "print(top[['N', 'S', 'dNdS_naive']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4098ff7-3a64-40b2-9a0e-3e530c0a9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ResourceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "87444447-a205-483e-ad7e-eb4e7ad7c46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: mysql-connector-python in /usr/local/lib/python3.8/site-packages (9.0.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d7a7086e-9294-4621-a076-9e237ed76bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to UCSC\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"genome-mysql.soe.ucsc.edu\",\n",
    "    user=\"genome\",\n",
    "    database=\"hg19\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Corrected SQL query\n",
    "query = \"\"\"\n",
    "SELECT name2, cdsStart, cdsEnd, exonStarts, exonEnds\n",
    "FROM refGene;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows, columns=[\"Hugo_Symbol\", \"cdsStart\", \"cdsEnd\", \"exonStarts\", \"exonEnds\"])\n",
    "\n",
    "# Compute CDS length per transcript\n",
    "def compute_cds_length(row):\n",
    "    exon_starts = row['exonStarts']\n",
    "    exon_ends = row['exonEnds']\n",
    "\n",
    "    # Decode from bytes to string if needed\n",
    "    if isinstance(exon_starts, bytes):\n",
    "        exon_starts = exon_starts.decode(\"utf-8\")\n",
    "    if isinstance(exon_ends, bytes):\n",
    "        exon_ends = exon_ends.decode(\"utf-8\")\n",
    "\n",
    "    # Process comma-separated strings\n",
    "    starts = list(map(int, exon_starts.strip(',').split(',')))\n",
    "    ends = list(map(int, exon_ends.strip(',').split(',')))\n",
    "    cds_start, cds_end = row['cdsStart'], row['cdsEnd']\n",
    "\n",
    "    length = 0\n",
    "    for s, e in zip(starts, ends):\n",
    "        overlap_start = max(s, cds_start)\n",
    "        overlap_end = min(e, cds_end)\n",
    "        if overlap_end > overlap_start:\n",
    "            length += (overlap_end - overlap_start)\n",
    "    return length\n",
    "\n",
    "\n",
    "df['cds_length'] = df.apply(compute_cds_length, axis=1)\n",
    "\n",
    "# Collapse multiple transcripts to max CDS per gene\n",
    "gene_lengths = (\n",
    "    df.groupby(\"Hugo_Symbol\")['cds_length']\n",
    "    .max()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Drop 0-length entries\n",
    "gene_lengths = gene_lengths[gene_lengths['cds_length'] > 0]\n",
    "\n",
    "# Save\n",
    "gene_lengths.to_csv(\"gene_coding_lengths.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "314b8c07-5f91-4401-bf96-7b1d62e2d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hugo_Symbol    N  S  cds_length  dNdS_corrected\n",
      "14396        TP53  169  2        1182       28.166667\n",
      "4223        ERBB2   33  1        3885       11.000000\n",
      "12847       SMAD4   29  1        1659        9.666667\n",
      "2426          CFH   28  1        3696        9.333333\n",
      "10207      PIK3CA   82  3        3207        9.111111\n",
      "2257         CDH9   25  1        2370        8.333333\n",
      "2773        CNTN4   25  1        3081        8.333333\n",
      "5570       GRIN3A   24  1        3348        8.000000\n",
      "13947       THSD1   23  1        2559        7.666667\n",
      "566         AMY2B   21  1        1536        7.000000\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Count N and S per gene\n",
    "counts = (\n",
    "    mut_df.groupby(['Hugo_Symbol', 'class'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .rename(columns={'syn': 'S', 'nonsyn': 'N'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# âœ… Merge mutation counts with gene sizes\n",
    "df = counts.merge(gene_lengths, on='Hugo_Symbol', how='inner')\n",
    "\n",
    "# Step 1: Estimate number of sites (opportunities)\n",
    "df['L_N'] = 0.75 * df['cds_length']\n",
    "df['L_S'] = 0.25 * df['cds_length']\n",
    "\n",
    "# Step 2: Compute normalized rates\n",
    "df['dN'] = df['N'] / df['L_N']\n",
    "df['dS'] = df['S'] / df['L_S']\n",
    "\n",
    "# Step 3: Compute size-adjusted dN/dS\n",
    "df = df[df['dS'] > 0]  # avoid division by zero\n",
    "df['dNdS_corrected'] = df['dN'] / df['dS']\n",
    "\n",
    "# Optional: sort for potential drivers\n",
    "top = df.sort_values('dNdS_corrected', ascending=False).head(10)\n",
    "print(top[['Hugo_Symbol', 'N', 'S', 'cds_length', 'dNdS_corrected']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "925fc3f2-4d98-43da-a307-7d1dfaa22354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hugo_Symbol    N  S  cds_length  dNdS_corrected\n",
      "14396        TP53  169  2        1182       28.166667\n",
      "4223        ERBB2   33  1        3885       11.000000\n",
      "12847       SMAD4   29  1        1659        9.666667\n",
      "2426          CFH   28  1        3696        9.333333\n",
      "10207      PIK3CA   82  3        3207        9.111111\n",
      "2257         CDH9   25  1        2370        8.333333\n",
      "2773        CNTN4   25  1        3081        8.333333\n",
      "5570       GRIN3A   24  1        3348        8.000000\n",
      "13947       THSD1   23  1        2559        7.666667\n",
      "566         AMY2B   21  1        1536        7.000000\n",
      "5827          HGF   19  1        2187        6.333333\n",
      "15217       VWA5A   19  1        2361        6.333333\n",
      "3987       EGFLAM   19  1        3054        6.333333\n",
      "8394         MYH1   19  1        5820        6.333333\n",
      "9394       OR4C16   19  1         933        6.333333\n",
      "9366       OR2T12   19  1         963        6.333333\n",
      "3287        DAAM1   18  1        3237        6.000000\n",
      "2732        CNGA4   18  1        1728        6.000000\n",
      "1767        CADM1   18  1        1416        6.000000\n",
      "11274       RASA1   18  1        3144        6.000000\n",
      "14541     TRIM49C   17  1        1359        5.666667\n",
      "3275       CYP7B1   17  1        1521        5.666667\n",
      "2723        CNBD1   17  1        1311        5.666667\n",
      "7649        MANEA   17  1        1389        5.666667\n",
      "13936       THOC2   17  1        4782        5.666667\n",
      "9949        PDE3B   17  1        3573        5.666667\n",
      "6680       KCNK10   16  1        1632        5.333333\n",
      "4224        ERBB3   48  3        4029        5.333333\n",
      "11486       RGPD3   16  1        5277        5.333333\n",
      "5022       GABRG2   16  1        1548        5.333333\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Estimate number of sites (opportunities)\n",
    "df['L_N'] = 0.75 * df['cds_length']\n",
    "df['L_S'] = 0.25 * df['cds_length']\n",
    "\n",
    "# Step 2: Compute normalized rates\n",
    "df['dN'] = df['N'] / df['L_N']\n",
    "df['dS'] = df['S'] / df['L_S']\n",
    "\n",
    "# Step 3: Compute size-adjusted dN/dS\n",
    "df = df[df['dS'] > 0]  # avoid division by zero\n",
    "df['dNdS_corrected'] = df['dN'] / df['dS']\n",
    "\n",
    "# Optional: sort for potential drivers\n",
    "top = df.sort_values('dNdS_corrected', ascending=False).head(30)\n",
    "print(top[['Hugo_Symbol', 'N', 'S', 'cds_length', 'dNdS_corrected']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e149a224-2639-4f6a-91be-a3030da10da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a6a9f-8128-454d-ac40-b9397fcd549b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00ef1c-efa2-4d15-a75a-93b69bb8f694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3df14e58-4391-412e-b04b-7500df2b129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_genes(mut_df):\n",
    "    shuffled_df = mut_df.copy()\n",
    "    original_genes = shuffled_df['Hugo_Symbol'].tolist()\n",
    "    np.random.shuffle(original_genes)\n",
    "    shuffled_df['Hugo_Symbol'] = original_genes\n",
    "    return shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805261c-62cf-4127-98ea-0192101a8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np ### warning this takes a really long time!!!\n",
    "n_permutations = 1000\n",
    "null_dnds_distributions = {}\n",
    "\n",
    "for _ in range(n_permutations):\n",
    "    shuffled_mut_df = shuffle_genes(mut_df.copy()) # Important: shuffle a copy\n",
    "    shuffled_counts = (\n",
    "        shuffled_mut_df.groupby(['Hugo_Symbol', 'class'])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .rename(columns={'syn': 'S', 'nonsyn': 'N'})\n",
    "        .reset_index()\n",
    "    )\n",
    "    if 'N' not in shuffled_counts.columns:\n",
    "        shuffled_counts['N'] = 0\n",
    "    if 'S' not in shuffled_counts.columns:\n",
    "        shuffled_counts['S'] = 0\n",
    "    shuffled_df_merged = shuffled_counts.merge(gene_lengths, on='Hugo_Symbol', how='inner')\n",
    "    shuffled_df_merged['L_N'] = 0.75 * shuffled_df_merged['cds_length']\n",
    "    shuffled_df_merged['L_S'] = 0.25 * shuffled_df_merged['cds_length']\n",
    "    shuffled_df_merged['dN'] = shuffled_df_merged['N'] / shuffled_df_merged['L_N']\n",
    "    shuffled_df_merged = shuffled_df_merged[shuffled_df_merged['L_S'] > 0] # Avoid division by zero\n",
    "    shuffled_df_merged['dS'] = shuffled_df_merged['S'] / shuffled_df_merged['L_S']\n",
    "    shuffled_df_merged = shuffled_df_merged[shuffled_df_merged['dS'] > 0] # Avoid division by zero\n",
    "    shuffled_df_merged['dNdS_corrected'] = shuffled_df_merged['dN'] / shuffled_df_merged['dS']\n",
    "\n",
    "    for gene in shuffled_df_merged['Hugo_Symbol']:\n",
    "        dnds = shuffled_df_merged.loc[shuffled_df_merged['Hugo_Symbol'] == gene, 'dNdS_corrected'].iloc[0]\n",
    "        if gene not in null_dnds_distributions:\n",
    "            null_dnds_distributions[gene] = []\n",
    "        null_dnds_distributions[gene].append(dnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a6775-8032-4996-a605-a28bad505fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = {}\n",
    "for gene, observed_dnds in df.set_index('Hugo_Symbol')['dNdS_corrected'].items():\n",
    "    if gene in null_dnds_distributions:\n",
    "        null_distribution = np.array(null_dnds_distributions[gene])\n",
    "        if not np.isnan(observed_dnds) and len(null_distribution) > 0:\n",
    "            # For positive selection (dN/dS > 1)\n",
    "            p_greater = np.mean(null_distribution >= observed_dnds)\n",
    "            # For negative selection (dN/dS < 1)\n",
    "            p_less = np.mean(null_distribution <= observed_dnds)\n",
    "            p_values[gene] = {'p_greater': p_greater, 'p_less': p_less}\n",
    "        else:\n",
    "            p_values[gene] = {'p_greater': np.nan, 'p_less': np.nan}\n",
    "    else:\n",
    "        p_values[gene] = {'p_greater': np.nan, 'p_less': np.nan}\n",
    "\n",
    "print(\"\\nP-values based on permutation:\")\n",
    "for gene, p_vals in p_values.items():\n",
    "    print(f\"{gene}: p_greater={p_vals['p_greater']:.4f}, p_less={p_vals['p_less']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c1e115-0ec5-401f-8946-9280c5e606e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "all_p_greater = np.array([p['p_greater'] for p in p_values.values() if not np.isnan(p['p_greater'])])\n",
    "gene_names_with_p = [gene for gene, p in p_values.items() if not np.isnan(p['p_greater'])]\n",
    "\n",
    "if len(all_p_greater) > 0:\n",
    "    reject, p_corrected, _, _ = multipletests(all_p_greater, method='fdr_bh')\n",
    "    corrected_p_greater_dict = dict(zip(gene_names_with_p, p_corrected))\n",
    "    print(\"\\nFDR-corrected p-values (greater):\")\n",
    "    for gene, p in corrected_p_greater_dict.items():\n",
    "        print(f\"{gene}: {p:.4f}\")\n",
    "\n",
    "# Repeat for p_less if you are interested in negative selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee801e7-9b86-49b5-bcb8-5e889a9b0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have 'corrected_p_greater_dict' and your 'df' DataFrame\n",
    "\n",
    "# Create a Pandas Series from the corrected p-values\n",
    "corrected_p_series = pd.Series(corrected_p_greater_dict)\n",
    "\n",
    "# Define a significance threshold\n",
    "significance_threshold = 0.1\n",
    "\n",
    "# Filter for significant genes based on FDR\n",
    "significant_p_values = corrected_p_series[corrected_p_series < significance_threshold]\n",
    "\n",
    "if not significant_p_values.empty:\n",
    "    print(\"\\nTop Potential Driver Genes (FDR < {}):\".format(significance_threshold))\n",
    "    # Merge the significant p-values with the dNdS_corrected from your original df\n",
    "    significant_drivers_df = pd.DataFrame({'FDR_p_value': significant_p_values})\n",
    "    drivers_with_dnds = significant_drivers_df.merge(\n",
    "        df[['Hugo_Symbol', 'dNdS_corrected']].set_index('Hugo_Symbol'),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how='inner'\n",
    "    ).sort_values(by='FDR_p_value')\n",
    "    print(drivers_with_dnds)\n",
    "else:\n",
    "    print(\"No genes found to be significant at FDR < {}\".format(significance_threshold))\n",
    "\n",
    "# Optional: Print top N by FDR with dN/dS\n",
    "top_n = 40\n",
    "top_genes_by_p = corrected_p_series.sort_values(ascending=True).head(top_n)\n",
    "if not top_genes_by_p.empty:\n",
    "    print(f\"\\nTop {top_n} Potential Driver Genes (by lowest FDR) with dN/dS:\")\n",
    "    top_n_drivers_df = pd.DataFrame({'FDR_p_value': top_genes_by_p})\n",
    "    top_n_with_dnds = top_n_drivers_df.merge(\n",
    "        df[['Hugo_Symbol', 'dNdS_corrected']].set_index('Hugo_Symbol'),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how='inner'\n",
    "    )\n",
    "    print(top_n_with_dnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553731b3-0238-45b1-8ea8-f8db05f973db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa032d-e30b-4ab8-87b3-e1c4180c15c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd3c84-d716-434d-92f1-0336ea4c342a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66dbe7-36ec-4d02-b0ac-5abc43eeeec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad5465-6169-4f07-8407-e5f4d4140511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36598d07-5d5c-4e5e-b927-dda05dc79a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4f638-1e24-4396-8384-833b5a450ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab1699-793a-4a03-af33-7e1aa8dbd7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13620fd-6adb-42b7-9a38-aba5cd42319b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c6671-975e-4312-8852-1a071dae9c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f241c4-62b4-4a45-99bf-9b63fa8ce364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ee783fe7-a905-4f81-8a26-76473b552930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2b182-8fe2-40ad-944d-93c6ad43ce0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44471fc2-0b6d-4c34-882d-c5cea7847a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414105fd-8035-487a-bed0-d630647d4df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a6f03-c9a8-4dcc-8759-ab5987a13f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e52a0-2f96-46ba-a4bc-7e3cff155ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf32091-0c6e-4439-80d7-0f8a5b59d856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e854a3a-1e9b-4441-9068-17452b86e874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e3074-c4ac-40b7-a0b8-fff24d1f1c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cf9c0-8867-415e-9d80-ca35731c5e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aafbf8-e1ed-4711-b0f4-e9d778a08a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c795975-9589-465a-bd6e-09d7f7091fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
